{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def orb_bf_match_and_find(query_img, train_img, query_img_filename, train_img_filename, min_matches): \n",
        "    # Scale train_img to be the same size as query_img\n",
        "    train_img = cv.resize(train_img, (query_img.shape[1], query_img.shape[0]))\n",
        "    # Create an ORB object\n",
        "    orb = cv.ORB_create()\n",
        "    \n",
        "    features1, des1 = orb.detectAndCompute(query_img, None)\n",
        "    features2, des2 = orb.detectAndCompute(train_img, None)\n",
        "\n",
        "    # Create Brute-Force matcher object\n",
        "    bf = cv.BFMatcher(cv.NORM_HAMMING)\n",
        "    matches = bf.knnMatch(des1, des2, k = 2)\n",
        "    \n",
        "    # Nearest neighbour ratio test to find good matches\n",
        "    good = []    \n",
        "    good_without_lists = []    \n",
        "    matches = [match for match in matches if len(match) == 2] \n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.8 * n.distance:\n",
        "            good.append([m])\n",
        "            good_without_lists.append(m)\n",
        "         \n",
        "    if len(good) >= min_matches:\n",
        "        # Draw a polygon around the recognized object\n",
        "        src_pts = np.float32([features1[m.queryIdx].pt for m in good_without_lists]).reshape(-1, 1, 2)\n",
        "        dst_pts = np.float32([features2[m.trainIdx].pt for m in good_without_lists]).reshape(-1, 1, 2)\n",
        "        \n",
        "        # Get the transformation matrix\n",
        "        M, _ = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
        "               \n",
        "        # Find the perspective transformation to get the corresponding points\n",
        "        h, w = query_img.shape[:2]\n",
        "        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
        "        dst = cv.perspectiveTransform(pts, M)\n",
        "        \n",
        "        train_img = cv.polylines(train_img, [np.int32(dst)], True, (0, 255, 0), 2, cv.LINE_AA)\n",
        "    else:\n",
        "        print('Not enough good matches are found - {}/{}'.format(len(good), min_matches))\n",
        "    \n",
        "    print('Total matches found: {}'.format(len(good)))        \n",
        "    result_img = cv.drawMatchesKnn(query_img, features1, train_img, features2, good, None, flags = 4)\n",
        "    cv.putText(result_img, 'Total matches found: {}'.format(len(good)), (200, 200), cv.FONT_HERSHEY_SIMPLEX, 10, (0, 0, 255), 2, cv.LINE_AA)\n",
        "    cv.imwrite('output/orb/bf/{}_and_{}.jpg'.format(query_img_filename, train_img_filename), result_img)\n",
        "\n",
        "def orb_bf_match_with_images_folder(template, template_filename, min_matches):\n",
        "    for filename in os.listdir('output/orb/bf'):\n",
        "        if filename.startswith(template_filename):\n",
        "            os.remove('output/orb/bf/' + filename)\n",
        "    for filename in os.listdir('images'):\n",
        "        img = cv.imread('images/' + filename)\n",
        "        filename_no_ext = os.path.splitext(filename)[0]\n",
        "        orb_bf_match_and_find(template, img, template_filename, filename_no_ext, min_matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not enough good matches are found - 8/10\n",
            "Total matches found: 8\n",
            "Not enough good matches are found - 9/10\n",
            "Total matches found: 9\n",
            "Not enough good matches are found - 3/10\n",
            "Total matches found: 3\n",
            "Not enough good matches are found - 8/10\n",
            "Total matches found: 8\n",
            "Not enough good matches are found - 8/10\n",
            "Total matches found: 8\n",
            "Not enough good matches are found - 8/10\n",
            "Total matches found: 8\n",
            "Total matches found: 21\n",
            "Total matches found: 16\n",
            "Total matches found: 12\n",
            "Total matches found: 29\n",
            "Total matches found: 49\n",
            "Total matches found: 17\n",
            "Not enough good matches are found - 5/10\n",
            "Total matches found: 5\n",
            "Not enough good matches are found - 9/10\n",
            "Total matches found: 9\n",
            "Not enough good matches are found - 3/10\n",
            "Total matches found: 3\n",
            "Not enough good matches are found - 9/10\n",
            "Total matches found: 9\n",
            "Not enough good matches are found - 5/10\n",
            "Total matches found: 5\n",
            "Not enough good matches are found - 2/10\n",
            "Total matches found: 2\n",
            "Total matches found: 14\n",
            "Total matches found: 12\n",
            "Total matches found: 15\n",
            "Total matches found: 25\n",
            "Total matches found: 33\n",
            "Total matches found: 24\n"
          ]
        }
      ],
      "source": [
        "# Running matching with remote control template\n",
        "min_matches = 10\n",
        "template = cv.imread('templates/remote-1.jpg')\n",
        "orb_bf_match_with_images_folder(template, 'remote-1', min_matches)\n",
        "template = cv.imread('templates/remote-2.jpg')\n",
        "orb_bf_match_with_images_folder(template, 'remote-2', min_matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not enough good matches are found - 18/25\n",
            "Total matches found: 18\n",
            "Not enough good matches are found - 19/25\n",
            "Total matches found: 19\n",
            "Total matches found: 31\n",
            "Not enough good matches are found - 23/25\n",
            "Total matches found: 23\n",
            "Not enough good matches are found - 17/25\n",
            "Total matches found: 17\n",
            "Not enough good matches are found - 13/25\n",
            "Total matches found: 13\n",
            "Not enough good matches are found - 11/25\n",
            "Total matches found: 11\n",
            "Total matches found: 40\n",
            "Not enough good matches are found - 20/25\n",
            "Total matches found: 20\n",
            "Not enough good matches are found - 11/25\n",
            "Total matches found: 11\n",
            "Not enough good matches are found - 12/25\n",
            "Total matches found: 12\n",
            "Total matches found: 27\n",
            "Not enough good matches are found - 23/25\n",
            "Total matches found: 23\n",
            "Not enough good matches are found - 11/25\n",
            "Total matches found: 11\n",
            "Not enough good matches are found - 18/25\n",
            "Total matches found: 18\n",
            "Not enough good matches are found - 20/25\n",
            "Total matches found: 20\n",
            "Not enough good matches are found - 14/25\n",
            "Total matches found: 14\n",
            "Not enough good matches are found - 13/25\n",
            "Total matches found: 13\n",
            "Not enough good matches are found - 16/25\n",
            "Total matches found: 16\n",
            "Total matches found: 25\n",
            "Total matches found: 26\n",
            "Not enough good matches are found - 12/25\n",
            "Total matches found: 12\n",
            "Not enough good matches are found - 11/25\n",
            "Total matches found: 11\n",
            "Total matches found: 31\n"
          ]
        }
      ],
      "source": [
        "# Running matching with earphone template\n",
        "min_matches = 25\n",
        "template = cv.imread('templates/earphone-1.jpg')\n",
        "orb_bf_match_with_images_folder(template, 'earphone-1', min_matches)\n",
        "template = cv.imread('templates/earphone-2.jpg')\n",
        "orb_bf_match_with_images_folder(template, 'earphone-2', min_matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not enough good matches are found - 7/8\n",
            "Total matches found: 7\n",
            "Not enough good matches are found - 2/8\n",
            "Total matches found: 2\n",
            "Total matches found: 9\n",
            "Total matches found: 11\n",
            "Not enough good matches are found - 4/8\n",
            "Total matches found: 4\n",
            "Total matches found: 8\n",
            "Total matches found: 8\n",
            "Not enough good matches are found - 7/8\n",
            "Total matches found: 7\n",
            "Not enough good matches are found - 7/8\n",
            "Total matches found: 7\n",
            "Not enough good matches are found - 6/8\n",
            "Total matches found: 6\n",
            "Total matches found: 8\n",
            "Total matches found: 15\n",
            "Not enough good matches are found - 7/8\n",
            "Total matches found: 7\n",
            "Total matches found: 8\n",
            "Not enough good matches are found - 5/8\n",
            "Total matches found: 5\n",
            "Not enough good matches are found - 6/8\n",
            "Total matches found: 6\n",
            "Not enough good matches are found - 4/8\n",
            "Total matches found: 4\n",
            "Not enough good matches are found - 2/8\n",
            "Total matches found: 2\n",
            "Not enough good matches are found - 6/8\n",
            "Total matches found: 6\n",
            "Not enough good matches are found - 4/8\n",
            "Total matches found: 4\n",
            "Not enough good matches are found - 4/8\n",
            "Total matches found: 4\n",
            "Total matches found: 9\n",
            "Total matches found: 12\n",
            "Not enough good matches are found - 6/8\n",
            "Total matches found: 6\n"
          ]
        }
      ],
      "source": [
        "# Running matching with elephant template\n",
        "min_matches = 8\n",
        "template = cv.imread('templates/elephant-1.jpg')\n",
        "orb_bf_match_with_images_folder(template, 'elephant-1', min_matches)\n",
        "template = cv.imread('templates/elephant-2.jpg')\n",
        "orb_bf_match_with_images_folder(template, 'elephant-2', min_matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def orb_flann_match_and_find(query_img, train_img, query_img_filename, train_img_filename, min_matches): \n",
        "    # Scale train_img to be the same size as query_img\n",
        "    train_img = cv.resize(train_img, (query_img.shape[1], query_img.shape[0]))\n",
        "    # Create an ORB object\n",
        "    orb = cv.ORB_create()\n",
        "    \n",
        "    features1, des1 = orb.detectAndCompute(query_img, None)\n",
        "    features2, des2 = orb.detectAndCompute(train_img, None)\n",
        "\n",
        "    # Create a FLANN matcher object\n",
        "    index_params = dict(algorithm = 6, table_number = 6, key_size = 12, multi_probe_level = 1)\n",
        "    search_params = dict()\n",
        "\n",
        "    flann = cv.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(des1, des2, k = 2)\n",
        "    \n",
        "    # Nearest neighbour ratio test to find good matches\n",
        "    good = []    \n",
        "    good_without_lists = []    \n",
        "    matches = [match for match in matches if len(match) == 2] \n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.8 * n.distance:\n",
        "            good.append([m])\n",
        "            good_without_lists.append(m)\n",
        "         \n",
        "    if len(good) >= min_matches:\n",
        "        # Draw a polygon around the recognized object\n",
        "        src_pts = np.float32([features1[m.queryIdx].pt for m in good_without_lists]).reshape(-1, 1, 2)\n",
        "        dst_pts = np.float32([features2[m.trainIdx].pt for m in good_without_lists]).reshape(-1, 1, 2)\n",
        "        \n",
        "        # Get the transformation matrix\n",
        "        M, _ = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
        "               \n",
        "        # Find the perspective transformation to get the corresponding points\n",
        "        h, w = query_img.shape[:2]\n",
        "        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
        "        dst = cv.perspectiveTransform(pts, M)\n",
        "        train_img = cv.polylines(train_img, [np.int32(dst)], True, (0, 255, 0), 2, cv.LINE_AA)\n",
        "    else:\n",
        "        print('Not enough good matches are found - {}/{}'.format(len(good), min_matches))\n",
        "    \n",
        "    print('Total matches found: {}'.format(len(good)))        \n",
        "    result_img = cv.drawMatchesKnn(query_img, features1, train_img, features2, good, None, flags = 4)\n",
        "\n",
        "    cv.putText(result_img, 'Total matches found: {}'.format(len(good)), (200, 200), cv.FONT_HERSHEY_SIMPLEX, 10, (0, 0, 255), 2, cv.LINE_AA)\n",
        "    cv.imwrite('output/orb/flann/{}_and_{}.jpg'.format(query_img_filename, train_img_filename), result_img)\n",
        "\n",
        "def orb_flann_match_with_images_folder(template, template_filename, min_matches):\n",
        "    for filename in os.listdir('output/orb/flann'):\n",
        "        if filename.startswith(template_filename):\n",
        "            os.remove('output/orb/flann/' + filename)\n",
        "    for filename in os.listdir('images'):\n",
        "        img = cv.imread('images/' + filename)\n",
        "        filename_no_ext = os.path.splitext(filename)[0]\n",
        "        orb_flann_match_and_find(template, img, template_filename, filename_no_ext, min_matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total matches found: 21\n",
            "Total matches found: 38\n",
            "Total matches found: 15\n",
            "Total matches found: 28\n",
            "Total matches found: 18\n",
            "Total matches found: 19\n",
            "Total matches found: 34\n",
            "Total matches found: 22\n",
            "Total matches found: 20\n",
            "Total matches found: 44\n",
            "Total matches found: 69\n",
            "Total matches found: 27\n",
            "Total matches found: 18\n",
            "Total matches found: 38\n",
            "Not enough good matches are found - 8/10\n",
            "Total matches found: 8\n",
            "Total matches found: 28\n",
            "Total matches found: 11\n",
            "Total matches found: 16\n",
            "Total matches found: 24\n",
            "Total matches found: 24\n",
            "Total matches found: 24\n",
            "Total matches found: 35\n",
            "Total matches found: 53\n",
            "Total matches found: 31\n"
          ]
        }
      ],
      "source": [
        "# Running matching with remote control template\n",
        "min_matches = 10\n",
        "template = cv.imread('templates/remote-1.jpg')\n",
        "orb_flann_match_with_images_folder(template, 'remote-1', min_matches)\n",
        "template = cv.imread('templates/remote-2.jpg')\n",
        "orb_flann_match_with_images_folder(template, 'remote-2', min_matches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sift_bf_match_and_find(query_img, train_img, query_img_filename, train_img_filename, min_matches): \n",
        "    # Scale train_img to be the same size as query_img\n",
        "    train_img = cv.resize(train_img, (query_img.shape[1], query_img.shape[0]))\n",
        "    # Create an SIFT object\n",
        "    sift = cv.SIFT_create()\n",
        "    \n",
        "    features1, des1 = sift.detectAndCompute(query_img, None)\n",
        "    features2, des2 = sift.detectAndCompute(train_img, None)\n",
        "\n",
        "    # Create a BFMatcher object\n",
        "    bf = cv.BFMatcher()\n",
        "    matches = bf.knnMatch(des1, des2, k = 2)\n",
        "    \n",
        "    # Nearest neighbour ratio test to find good matches\n",
        "    good = []    \n",
        "    good_without_lists = []    \n",
        "    matches = [match for match in matches if len(match) == 2] \n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.8 * n.distance:\n",
        "            good.append([m])\n",
        "            good_without_lists.append(m)\n",
        "         \n",
        "    if len(good) >= min_matches:\n",
        "        # Draw a polygon around the recognized object\n",
        "        src_pts = np.float32([features1[m.queryIdx].pt for m in good_without_lists]).reshape(-1, 1, 2)\n",
        "        dst_pts = np.float32([features2[m.trainIdx].pt for m in good_without_lists]).reshape(-1, 1, 2)\n",
        "        \n",
        "        # Get the transformation matrix\n",
        "        M, _ = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
        "               \n",
        "        # Find the perspective transformation to get the corresponding points\n",
        "        h, w = query_img.shape[:2]\n",
        "        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
        "        dst = cv.perspectiveTransform(pts, M)\n",
        "        train_img = cv.polylines(train_img, [np.int32(dst)], True, (0, 255, 0), 2, cv.LINE_AA)\n",
        "    else:\n",
        "        print('Not enough good matches are found - {}/{}'.format(len(good), min_matches))\n",
        "    \n",
        "    print('Total matches found: {}'.format(len(good)))\n",
        "\n",
        "    result_img = cv.drawMatchesKnn(query_img, features1, train_img, features2, good, None, flags = 4)\n",
        "    cv.putText(result_img, 'Total matches found: {}'.format(len(good)), (200, 200), cv.FONT_HERSHEY_SIMPLEX, 10, (0, 0, 255), 2, cv.LINE_AA)\n",
        "    cv.imwrite('output/sift/bf/{}_and_{}.jpg'.format(query_img_filename, train_img_filename), result_img)\n",
        "\n",
        "def sift_bf_match_with_images_folder(template, template_filename, min_matches):\n",
        "    for filename in os.listdir('output/sift/bf'):\n",
        "        if filename.startswith(template_filename):\n",
        "            os.remove('output/sift/bf/' + filename)\n",
        "    for filename in os.listdir('images'):\n",
        "        img = cv.imread('images/' + filename)\n",
        "        filename_no_ext = os.path.splitext(filename)[0]\n",
        "        sift_bf_match_and_find(template, img, template_filename, filename_no_ext, min_matches)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total matches found: 238\n",
            "Total matches found: 209\n",
            "Total matches found: 454\n",
            "Total matches found: 266\n",
            "Total matches found: 283\n",
            "Total matches found: 462\n",
            "Total matches found: 236\n",
            "Total matches found: 204\n",
            "Total matches found: 226\n",
            "Total matches found: 222\n",
            "Total matches found: 258\n",
            "Total matches found: 183\n",
            "Total matches found: 1523\n",
            "Total matches found: 1318\n",
            "Total matches found: 2248\n",
            "Total matches found: 1953\n",
            "Total matches found: 1992\n",
            "Total matches found: 2399\n",
            "Total matches found: 1457\n"
          ]
        }
      ],
      "source": [
        "#Running matching with earphone template\n",
        "min_matches = 10\n",
        "template = cv.imread('templates/earphone-1.jpg')\n",
        "sift_bf_match_with_images_folder(template, 'earphone-1', min_matches)\n",
        "template = cv.imread('templates/earphone-2.jpg')\n",
        "sift_bf_match_with_images_folder(template, 'earphone-2', min_matches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sift_flann_match_and_find(query_img, train_img, query_img_filename, train_img_filename, min_matches): \n",
        "    # Scale train_img to be the same size as query_img\n",
        "    train_img = cv.resize(train_img, (query_img.shape[1], query_img.shape[0]))\n",
        "    # Create an SIFT object\n",
        "    sift = cv.SIFT_create()\n",
        "    \n",
        "    features1, des1 = sift.detectAndCompute(query_img, None)\n",
        "    features2, des2 = sift.detectAndCompute(train_img, None)\n",
        "\n",
        "    # Create a FLANN matcher object\n",
        "    index_params = dict(algorithm = 0, trees = 5)\n",
        "    search_params = dict(checks = 50)\n",
        "    flann = cv.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(des1, des2, k = 2)\n",
        "    \n",
        "    # Nearest neighbour ratio test to find good matches\n",
        "    good = []    \n",
        "    good_without_lists = []    \n",
        "    matches = [match for match in matches if len(match) == 2] \n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.8 * n.distance:\n",
        "            good.append([m])\n",
        "            good_without_lists.append(m)\n",
        "         \n",
        "    if len(good) >= min_matches:\n",
        "        # Draw a polygon around the recognized object\n",
        "        src_pts = np.float32([features1[m.queryIdx].pt for m in good_without_lists]).reshape(-1, 1, 2)\n",
        "        dst_pts = np.float32([features2[m.trainIdx].pt for m in good_without_lists]).reshape(-1, 1, 2)\n",
        "        \n",
        "        # Get the transformation matrix\n",
        "        M, _ = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
        "               \n",
        "        # Find the perspective transformation to get the corresponding points\n",
        "        h, w = query_img.shape[:2]\n",
        "        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
        "        dst = cv.perspectiveTransform(pts, M)\n",
        "        train_img = cv.polylines(train_img, [np.int32(dst)], True, (0, 255, 0), 2, cv.LINE_AA)\n",
        "    else:\n",
        "        print('Not enough good matches are found - {}/{}'.format(len(good), min_matches))\n",
        "\n",
        "    print('Total matches found: {}'.format(len(good)))\n",
        "\n",
        "    result_img = cv.drawMatchesKnn(query_img, features1, train_img, features2, good, None, flags = 4)\n",
        "    cv.putText(result_img, 'Total matches found: {}'.format(len(good)), (200, 200), cv.FONT_HERSHEY_SIMPLEX, 10, (0, 0, 255), 2, cv.LINE_AA)\n",
        "    cv.imwrite('output/sift/flann/{}_and_{}.jpg'.format(query_img_filename, train_img_filename), result_img)\n",
        "    \n",
        "def sift_flann_match_with_images_folder(template, template_filename, min_matches):\n",
        "    for filename in os.listdir('output/sift/flann'):\n",
        "        if filename.startswith(template_filename):\n",
        "            os.remove('output/sift/flann/' + filename)\n",
        "    for filename in os.listdir('images'):\n",
        "        img = cv.imread('images/' + filename)\n",
        "        filename_no_ext = os.path.splitext(filename)[0]\n",
        "        sift_flann_match_and_find(template, img, template_filename, filename_no_ext, min_matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Running matching with elephant template\n",
        "min_matches = 10\n",
        "template = cv.imread('templates/elephant-1.jpg')\n",
        "sift_flann_match_with_images_folder(template, 'elephant-1', min_matches)\n",
        "template = cv.imread('templates/elephant-2.jpg')\n",
        "sift_flann_match_with_images_folder(template, 'elephant-2', min_matches)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "018f7a4aa4ca64966fd4977030ab30818634fc07475ea8f2b454d33c333ddf58"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
